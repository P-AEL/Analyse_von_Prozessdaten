{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.56720276e+02, 1.00000000e+02, 9.54861641e-02, ...,\n",
       "         0.00000000e+00, 1.57335068e+02, 1.21063965e+02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.98611641e-02, 2.40740752e+00, 3.66257591e+01],\n",
       "        [3.65107536e+01, 2.01963733e+03, 2.00000000e+03, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.83731186e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.23379627e-02, 2.40227127e+00, 1.50000000e+01],\n",
       "        [1.00000000e+01, 1.09591886e-01, 2.00000003e-01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [7.23379627e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.00000003e-01, 0.00000000e+00, 1.72441127e-03]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tank_training_data = pd.read_pickle(r\"C:\\Users\\t-ehm\\iCloudDrive\\Studium\\Data_Science_Semester4\\Analyse_von_Prozess_und_Produktdaten\\Analyse_von_Prozessdaten\\development\\setup\\current_tank_data.pkl\")\n",
    "\n",
    "# simulates new data coming in\n",
    "new_data = pd.read_csv(r\"C:\\Users\\t-ehm\\iCloudDrive\\Studium\\Data_Science_Semester4\\Analyse_von_Prozess_und_Produktdaten\\Analyse_von_Prozessdaten\\Paul\\Batch_76.csv\")\n",
    "\n",
    "# Daten aus dem aktuellen Batch ggf. aus Legacy Batch holen und preprocessing durchf√ºhren\n",
    "if new_data.iloc[0][\"CuStepNo ValueY\"] == 1 and tank_training_data.iloc[-1][\"CuStepNo ValueY\"] == 3:\n",
    "    data_to_analyse = new_data\n",
    "else:\n",
    "    newest_batch = tank_training_data.iloc[-1][\"Batch\"]\n",
    "    data_to_analyse = pd.concat([tank_training_data[tank_training_data[\"Batch\"] == newest_batch], new_data])\n",
    "    tank_training_data = tank_training_data[tank_training_data[\"Batch\"] != newest_batch]\n",
    "\n",
    "data_to_analyse.drop(columns=[\"DeviationID ValueY\", \"CuStepNo ValueY\", \"timestamp\", \"Unnamed: 0\"], inplace=True)\n",
    "data_to_analyse.to_numpy().reshape(1,39,data_to_analyse.__len__())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
